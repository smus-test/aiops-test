# This workflow will build the marketing classification model and register to model registry.
# Includes MLflow tracking integration.

name: Marketing Classification Pipeline Build
run-name: ${{ github.actor }} is building marketing classification model

on:
  workflow_dispatch:
    inputs:
      logLevel:
        description: 'Log level'
        required: true
        default: 'warning'
        type: choice
        options:
          - info
          - warning
          - debug
  push:
    branches: [ main ]
    paths:
      - 'ml_pipelines/**'
      - 'source_scripts/**'
  pull_request:
    branches: [ main ]
    paths:
      - 'ml_pipelines/**'
      - 'source_scripts/**'

permissions:
  id-token: write
  contents: read

jobs:
  check-trigger:
    runs-on: ubuntu-latest
    outputs:
      pipeline_enabled: ${{ steps.check.outputs.pipeline_enabled }}
    steps:
    - name: Check Pipeline Execution Trigger
      id: check
      run: |
        TRIGGER_EXECUTION="${{ vars.TRIGGER_PIPELINE_EXECUTION }}"
        echo "Pipeline execution trigger status: ${TRIGGER_EXECUTION}"
        
        if [ "$TRIGGER_EXECUTION" != "true" ]; then
          echo "Pipeline execution is disabled."
          echo "To enable pipeline execution:"
          echo "   1. Update Glue database and table names in GitHub secrets"
          echo "   2. Go to Settings → Secrets and variables → Actions → Variables tab"
          echo "   3. Set TRIGGER_PIPELINE_EXECUTION variable to 'true'"
          echo "   4. Re-run this workflow or push new changes"
          echo "pipeline_enabled=false" >> $GITHUB_OUTPUT
        else
          echo "Pipeline execution is enabled. Proceeding with build..."
          echo "pipeline_enabled=true" >> $GITHUB_OUTPUT
        fi

  GitHub-Actions-Classification-Build:
    needs: check-trigger
    if: needs.check-trigger.outputs.pipeline_enabled == 'true'
    runs-on: ubuntu-latest

    steps:
    - run: echo "Building Marketing Classification Pipeline"
    - uses: actions/checkout@v4
    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: "3.11"
    - name: Configure AWS Credentials via OIDC
      uses: aws-actions/configure-aws-credentials@v4
      with:
          role-to-assume: ${{secrets.OIDC_ROLE_GITHUB_WORKFLOW}}
          aws-region: ${{secrets.REGION}}
    - name: Install pip dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r ./ml_pipelines/requirements.txt

    - name: Create Requirements Directory
      run: |
        mkdir -p source_scripts/preprocessing/prepare_marketing_data/requirements
        echo "awswrangler==2.16.1" > source_scripts/preprocessing/prepare_marketing_data/requirements/requirements.txt
        echo "pymysql" >> source_scripts/preprocessing/prepare_marketing_data/requirements/requirements.txt
        echo "pandas==1.1.3" >> source_scripts/preprocessing/prepare_marketing_data/requirements/requirements.txt

    - name: Upload Files to S3
      run: |
        # Upload requirements and code
        aws s3 cp source_scripts/preprocessing/prepare_marketing_data/main.py s3://${{secrets.ARTIFACT_BUCKET}}/SMUSMLOPS/requirements-preprocess/input/code/main.py
        aws s3 cp --recursive source_scripts/preprocessing/prepare_marketing_data/requirements s3://${{secrets.ARTIFACT_BUCKET}}/SMUSMLOPS/requirements-preprocess/input/dependencies/

    - name: Run Marketing Classification Pipeline
      env:
        REGION: ${{ secrets.REGION }}
        SAGEMAKER_PROJECT_NAME: ${{ secrets.SAGEMAKER_PROJECT_NAME }}
        SAGEMAKER_PROJECT_ID: ${{ secrets.SAGEMAKER_PROJECT_ID }}
        AMAZON_DATAZONE_DOMAIN: ${{ secrets.AMAZON_DATAZONE_DOMAIN }}
        AMAZON_DATAZONE_SCOPENAME: ${{ secrets.AMAZON_DATAZONE_SCOPENAME }}
        SAGEMAKER_DOMAIN_ARN: ${{ secrets.SAGEMAKER_DOMAIN_ARN }}
        SAGEMAKER_SPACE_ARN: ${{ secrets.SAGEMAKER_SPACE_ARN }}
        AMAZON_DATAZONE_PROJECT: ${{ secrets.AMAZON_DATAZONE_PROJECT }}
        MODEL_PACKAGE_GROUP_NAME: ${{ secrets.MODEL_PACKAGE_GROUP_NAME }}
        ARTIFACT_BUCKET: ${{ secrets.ARTIFACT_BUCKET }}
        SAGEMAKER_PIPELINE_ROLE_ARN: ${{ secrets.SAGEMAKER_PIPELINE_ROLE_ARN }}
        GLUE_DATABASE: ${{ secrets.GLUE_DATABASE }}
        GLUE_TABLE: ${{ secrets.GLUE_TABLE }}
        MLFLOW_TRACKING_ARN: ${{ secrets.MLFLOW_TRACKING_ARN }}
      run: |
        export PYTHONUNBUFFERED=TRUE
        export SAGEMAKER_PROJECT_NAME_ID="${SAGEMAKER_PROJECT_NAME}-${SAGEMAKER_PROJECT_ID}"
        export PIPELINE_NAME="marketing-classification-${SAGEMAKER_PROJECT_ID}"
        
        echo "=== Starting Marketing Classification Pipeline ==="
        python ./ml_pipelines/run_pipeline.py \
          --module-name training.pipeline \
          --role-arn "${SAGEMAKER_PIPELINE_ROLE_ARN}" \
          --mlflow-tracking-arn "${MLFLOW_TRACKING_ARN}" \
          --tags '[{"Key":"sagemaker:project-name", "Value":"'"${SAGEMAKER_PROJECT_NAME}"'"}, {"Key":"sagemaker:project-id", "Value":"'"${SAGEMAKER_PROJECT_ID}"'"}, {"Key":"AmazonDataZoneDomain", "Value":"'"${AMAZON_DATAZONE_DOMAIN}"'"}, {"Key":"AmazonDataZoneScopeName", "Value":"'"${AMAZON_DATAZONE_SCOPENAME}"'"}, {"Key":"sagemaker:domain-arn", "Value":"'"${SAGEMAKER_DOMAIN_ARN}"'"}, {"Key":"sagemaker:space-arn", "Value":"'"${SAGEMAKER_SPACE_ARN}"'"}, {"Key":"AmazonDataZoneProject", "Value":"'"${AMAZON_DATAZONE_PROJECT}"'"}]' \
          --kwargs '{"region":"'"${REGION}"'","role":"'"${SAGEMAKER_PIPELINE_ROLE_ARN}"'","default_bucket":"'"${ARTIFACT_BUCKET}"'","pipeline_name":"'"${PIPELINE_NAME}"'","model_package_group_name":"'"${MODEL_PACKAGE_GROUP_NAME}"'","base_job_prefix":"MarketingClassification","glue_database_name":"'"${GLUE_DATABASE}"'","glue_table_name":"'"${GLUE_TABLE}"'","mlflow_tracking_arn":"'"${MLFLOW_TRACKING_ARN}"'"}'
        
        echo "Pipeline started successfully. Pipeline name: ${PIPELINE_NAME}"


    - name: Monitor Pipeline Execution
      env:
        REGION: ${{ secrets.REGION }}
        SAGEMAKER_PROJECT_ID: ${{ secrets.SAGEMAKER_PROJECT_ID }}
      run: |
        export PIPELINE_NAME="marketing-classification-${SAGEMAKER_PROJECT_ID}"
        
        echo "=== Monitoring Pipeline Execution ==="
        echo "Pipeline Name: ${PIPELINE_NAME}"
        
        # Get the latest execution ARN
        EXECUTION_ARN=$(aws sagemaker list-pipeline-executions \
          --pipeline-name "${PIPELINE_NAME}" \
          --region "${REGION}" \
          --max-items 1 \
          --query 'PipelineExecutionSummaries[0].PipelineExecutionArn' \
          --output text)
        
        if [ "$EXECUTION_ARN" = "None" ] || [ -z "$EXECUTION_ARN" ]; then
          echo "Error: Could not find pipeline execution"
          exit 1
        fi
        
        EXECUTION_ARN=$(echo "$EXECUTION_ARN" | tr -d '\n' | sed 's/None$//')
        echo "Monitoring execution: ${EXECUTION_ARN}"
        
        # Monitor pipeline execution status
        MAX_WAIT_TIME=3600
        WAIT_INTERVAL=30
        ELAPSED_TIME=0
        
        while [ $ELAPSED_TIME -lt $MAX_WAIT_TIME ]; do
          STATUS=$(aws sagemaker describe-pipeline-execution \
            --pipeline-execution-arn "${EXECUTION_ARN}" \
            --region "${REGION}" \
            --query 'PipelineExecutionStatus' \
            --output text)
          
          echo "Pipeline Status: ${STATUS} (Elapsed: ${ELAPSED_TIME}s)"
          
          case $STATUS in
            "Succeeded")
              echo "Pipeline execution completed successfully!"
              aws sagemaker describe-pipeline-execution \
                --pipeline-execution-arn "${EXECUTION_ARN}" \
                --region "${REGION}" \
                --query '{Status: PipelineExecutionStatus, StartTime: CreationTime, EndTime: LastModifiedTime}' \
                --output table
              exit 0
              ;;
            "Failed"|"Stopped")
              echo "Pipeline execution failed with status: ${STATUS}"
              FAILURE_REASON=$(aws sagemaker describe-pipeline-execution \
                --pipeline-execution-arn "${EXECUTION_ARN}" \
                --region "${REGION}" \
                --query 'FailureReason' \
                --output text)
              
              if [ "$FAILURE_REASON" != "None" ] && [ -n "$FAILURE_REASON" ]; then
                echo "Failure Reason: ${FAILURE_REASON}"
              fi
              
              aws sagemaker list-pipeline-execution-steps \
                --pipeline-execution-arn "${EXECUTION_ARN}" \
                --region "${REGION}" \
                --query 'PipelineExecutionSteps[?StepStatus==`Failed`].{StepName: StepName, Status: StepStatus, FailureReason: FailureReason}' \
                --output table
              exit 1
              ;;
            "Executing"|"Stopping")
              sleep $WAIT_INTERVAL
              ELAPSED_TIME=$((ELAPSED_TIME + WAIT_INTERVAL))
              ;;
            *)
              sleep $WAIT_INTERVAL
              ELAPSED_TIME=$((ELAPSED_TIME + WAIT_INTERVAL))
              ;;
          esac
        done
        
        echo "Timeout: Pipeline execution exceeded maximum wait time"
        exit 1

    - run: echo "Job status is ${{ job.status }}."
