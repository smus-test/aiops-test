# This workflow will build the model and register to model registry.
# Note: This gihub actions job executes only for changes to specific paths. 
# Change the paths as you see fit for your use-cases.

name: Sagemaker Pipeline build SMUS project
run-name: ${{ github.actor }} is building in SMUS

on:
  workflow_dispatch:
    inputs:
      logLevel:
        description: 'Log level'
        required: true
        default: 'warning'
        type: choice
        options:
          - info
          - warning
          - debug
  push:
    branches: [ main ]
    paths:
      - 'ml_pipelines/**'
      - 'source_scripts/**'
  pull_request:
    branches: [ main ]
    paths:
      - 'ml_pipelines/**'
      - 'source_scripts/**'

permissions:
  id-token: write
  contents: read

jobs:
  GitHub-Actions-SMUS-Build:

    runs-on: ubuntu-latest

    steps:
    - run: echo "The job was automatically triggered by a ${{ github.event_name }} event."
    - run: echo "This job is now running on a ${{ runner.os }} server hosted by GitHub!"
    - run: echo "The name of your branch is ${{ github.ref }} and your repository is ${{ github.repository }}."
    - run: echo "The commit message for the event -\n ${{ github.event.head_commit.message }}"
    - uses: actions/checkout@v4
    - name: Check out repository code
      uses: actions/checkout@v4
    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: "3.11"
    - name: Configure Dev Account AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
          role-to-assume: ${{secrets.OIDC_ROLE_GITHUB_WORKFLOW}}
          aws-region: ${{secrets.REGION}}
    - name: Install pip dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r ./ml_pipelines/requirements.txt

    - name: Create Requirements Directory
      run: |
        mkdir -p source_scripts/preprocessing/prepare_abalone_data/requirements
        echo "awswrangler==2.16.1" > source_scripts/preprocessing/prepare_abalone_data/requirements/requirements.txt
        echo "pymysql" >> source_scripts/preprocessing/prepare_abalone_data/requirements/requirements.txt
        echo "pandas==1.1.3" >> source_scripts/preprocessing/prepare_abalone_data/requirements/requirements.txt
    - name: Upload Files to S3
      run: |
        # Upload dataset
        python ./ml_pipelines/data/upload_s3_util.py --s3_bucket ${{secrets.ARTIFACT_BUCKET}}
        
        # Upload requirements and code
        aws s3 cp source_scripts/preprocessing/prepare_abalone_data/main.py s3://${{secrets.ARTIFACT_BUCKET}}/SMUSMLOPS/requirements-preprocess/input/code/main.py
        aws s3 cp --recursive source_scripts/preprocessing/prepare_abalone_data/requirements s3://${{secrets.ARTIFACT_BUCKET}}/SMUSMLOPS/requirements-preprocess/input/dependencies/
    - name: List files in the repository
      run: |
        ls ${{ github.workspace }}
    - name: Run Sagemaker Pipeline
      env:
        REGION: ${{ secrets.REGION }}
        SAGEMAKER_PROJECT_NAME: ${{ secrets.SAGEMAKER_PROJECT_NAME }}
        SAGEMAKER_PROJECT_ID: ${{ secrets.SAGEMAKER_PROJECT_ID }}
        AMAZON_DATAZONE_DOMAIN: ${{ secrets.AMAZON_DATAZONE_DOMAIN }}
        AMAZON_DATAZONE_SCOPENAME: ${{ secrets.AMAZON_DATAZONE_SCOPENAME }}
        SAGEMAKER_DOMAIN_ARN: ${{ secrets.SAGEMAKER_DOMAIN_ARN }}
        SAGEMAKER_SPACE_ARN: ${{ secrets.SAGEMAKER_SPACE_ARN }}
        AMAZON_DATAZONE_PROJECT: ${{ secrets.AMAZON_DATAZONE_PROJECT }}
        MODEL_PACKAGE_GROUP_NAME: ${{ secrets.MODEL_PACKAGE_GROUP_NAME }}
        ARTIFACT_BUCKET: ${{ secrets.ARTIFACT_BUCKET }}
        SAGEMAKER_PIPELINE_ROLE_ARN: ${{ secrets.SAGEMAKER_PIPELINE_ROLE_ARN }}
        GLUE_DATABASE: ${{ secrets.GLUE_DATABASE }}
        GLUE_TABLE: ${{ secrets.GLUE_TABLE }}
      run: |
        export PYTHONUNBUFFERED=TRUE
        export SAGEMAKER_PROJECT_NAME_ID="${SAGEMAKER_PROJECT_NAME}-${SAGEMAKER_PROJECT_ID}"
        
        echo "=== Starting Glue Catalog Pipeline ==="
        python ./ml_pipelines/run_pipeline.py \
          --module-name training.pipeline \
          --role-arn "${SAGEMAKER_PIPELINE_ROLE_ARN}" \
          --tags '[{"Key":"sagemaker:project-name", "Value":"'"${SAGEMAKER_PROJECT_NAME}"'"}, {"Key":"sagemaker:project-id", "Value":"'"${SAGEMAKER_PROJECT_ID}"'"}, {"Key":"AmazonDataZoneDomain", "Value":"'"${AMAZON_DATAZONE_DOMAIN}"'"}, {"Key":"AmazonDataZoneScopeName", "Value":"'"${AMAZON_DATAZONE_SCOPENAME}"'"}, {"Key":"sagemaker:domain-arn", "Value":"'"${SAGEMAKER_DOMAIN_ARN}"'"}, {"Key":"sagemaker:space-arn", "Value":"'"${SAGEMAKER_SPACE_ARN}"'"}, {"Key":"AmazonDataZoneProject", "Value":"'"${AMAZON_DATAZONE_PROJECT}"'"}]' \
          --kwargs '{"region":"'"${REGION}"'","role":"'"${SAGEMAKER_PIPELINE_ROLE_ARN}"'","default_bucket":"'"${ARTIFACT_BUCKET}"'","pipeline_name":"githubactions-'"${SAGEMAKER_PROJECT_ID}"'","model_package_group_name":"'"${MODEL_PACKAGE_GROUP_NAME}"'","base_job_prefix":"SMUSMLOPS","glue_database_name":"'"${GLUE_DATABASE}"'","glue_table_name":"'"${GLUE_TABLE}"'"}'
        
        echo "ðŸŒŸ Success: Glue Catalog Pipeline execution completed."
    - run: echo "This github action job's status is ${{ job.status }}."
